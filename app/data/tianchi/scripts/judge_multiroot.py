import csv
import argparse
from collections import defaultdict

def count_multi_root_traces(csv_file_path, trace_col="TraceID", span_col="SpanID", parent_col="ParentID"):
    """
    ç»Ÿè®¡CSVä¸­å­˜åœ¨å¤šæ ¹èŠ‚ç‚¹çš„Traceæ•°é‡ï¼ˆæ ¹èŠ‚ç‚¹å®šä¹‰ï¼šParentID=-1 æˆ– ParentIDåœ¨å½“å‰Traceä¸­æ— åŒ¹é…çš„SpanIDï¼‰
    
    Args:
        csv_file_path: CSVæ–‡ä»¶è·¯å¾„
        trace_col: TraceIDåˆ—åï¼ˆé»˜è®¤TraceIDï¼‰
        span_col: SpanIDåˆ—åï¼ˆé»˜è®¤SpanIDï¼‰
        parent_col: ParentIDåˆ—åï¼ˆé»˜è®¤ParentIDï¼‰
    """
    # æ­¥éª¤1ï¼šå…ˆè¯»å–æ‰€æœ‰æ•°æ®ï¼ŒæŒ‰TraceIDåˆ†ç»„å­˜å‚¨ï¼ˆSpanIDå’ŒParentIDï¼‰
    trace_data = defaultdict(list)  # key=TraceID, value=[(SpanID, ParentID), ...]
    valid_traces = set()

    try:
        with open(csv_file_path, 'r', encoding='utf-8') as f:
            csv_reader = csv.DictReader(f)
            headers = csv_reader.fieldnames
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = [trace_col, span_col, parent_col]
            missing_cols = [col for col in required_cols if col not in headers]
            if missing_cols:
                print(f"âŒ é”™è¯¯ï¼šCSVæ–‡ä»¶ä¸­ç¼ºå¤±å¿…è¦åˆ— â†’ {missing_cols}")
                print(f"   å½“å‰CSVåŒ…å«çš„åˆ—ï¼š{headers}")
                return
            
            # éå†æ‰€æœ‰è¡Œï¼ŒæŒ‰TraceIDåˆ†ç»„
            row_num = 0
            for row in csv_reader:
                row_num += 1
                # æå–å¹¶æ¸…æ´—å­—æ®µ
                trace_id = row[trace_col].strip() if row[trace_col] is not None else ""
                span_id = row[span_col].strip() if row[span_col] is not None else ""
                parent_id = row[parent_col].strip() if row[parent_col] is not None else ""
                
                # è·³è¿‡ç©ºTraceIDæˆ–ç©ºSpanIDçš„è¡Œï¼ˆæ— æ•ˆæ•°æ®ï¼‰
                if not trace_id:
                    print(f"âš ï¸  è­¦å‘Šï¼šç¬¬{row_num}è¡ŒTraceIDä¸ºç©ºï¼Œå·²è·³è¿‡")
                    continue
                if not span_id:
                    print(f"âš ï¸  è­¦å‘Šï¼šç¬¬{row_num}è¡ŒSpanIDä¸ºç©ºï¼ˆTraceID={trace_id}ï¼‰ï¼Œå·²è·³è¿‡")
                    continue
                
                trace_data[trace_id].append((span_id, parent_id))
                valid_traces.add(trace_id)

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ '{csv_file_path}'ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        return
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return

    # æ­¥éª¤2ï¼šéå†æ¯ä¸ªTraceï¼Œç»Ÿè®¡æ ¹èŠ‚ç‚¹æ•°é‡
    trace_root_count = defaultdict(int)
    multi_root_traces = []

    for trace_id in valid_traces:
        spans = trace_data[trace_id]
        # æå–å½“å‰Traceä¸‹çš„æ‰€æœ‰SpanIDï¼ˆç”¨äºåˆ¤æ–­ParentIDæ˜¯å¦å­˜åœ¨ï¼‰
        span_ids_in_trace = {span_id for span_id, _ in spans}
        root_count = 0

        # éå†å½“å‰Traceçš„æ¯ä¸ªSpanï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºæ ¹èŠ‚ç‚¹
        for span_id, parent_id in spans:
            # æ ¹èŠ‚ç‚¹åˆ¤å®šè§„åˆ™ï¼šParentID=-1 æˆ– ParentIDä¸åœ¨å½“å‰Traceçš„SpanIDåˆ—è¡¨ä¸­
            if parent_id == "-1" or parent_id not in span_ids_in_trace:
                root_count += 1
        
        trace_root_count[trace_id] = root_count
        # æ ¹èŠ‚ç‚¹æ•°â‰¥2åˆ™åˆ¤å®šä¸ºå¤šæ ¹Trace
        if root_count >= 2:
            multi_root_traces.append(trace_id)

    # æ­¥éª¤3ï¼šè¾“å‡ºç»Ÿè®¡ç»“æœ
    total_trace_count = len(valid_traces)
    multi_root_count = len(multi_root_traces)

    print("=" * 70)
    print(f"ğŸ“Š Traceå¤šæ ¹èŠ‚ç‚¹ç»Ÿè®¡ç»“æœï¼ˆæ ¹èŠ‚ç‚¹å®šä¹‰ï¼šParentID=-1 æˆ– ParentIDæ— åŒ¹é…SpanIDï¼‰")
    print("=" * 70)
    print(f"ğŸ“ˆ æ€»è®¡æœ‰æ•ˆTraceæ•°é‡ï¼š{total_trace_count}")
    print(f"ğŸ”´ å­˜åœ¨å¤šæ ¹èŠ‚ç‚¹çš„Traceæ•°é‡ï¼š{multi_root_count}")
    print(f"ğŸ“ å¤šæ ¹Traceå æ¯”ï¼š{multi_root_count/total_trace_count*100:.2f}%" if total_trace_count > 0 else "ğŸ“ å¤šæ ¹Traceå æ¯”ï¼š0.00%")
    
    # å¯é€‰ï¼šè¾“å‡ºå‰10ä¸ªå¤šæ ¹Traceçš„æ ¹èŠ‚ç‚¹æ•°ï¼ˆä¾¿äºéªŒè¯ï¼‰
    if multi_root_count > 0:
        print("\nğŸ” å‰10ä¸ªå¤šæ ¹Traceçš„æ ¹èŠ‚ç‚¹æ•°ï¼ˆéªŒè¯ç”¨ï¼‰ï¼š")
        # æŒ‰æ ¹èŠ‚ç‚¹æ•°é™åºæ’åº
        sorted_multi_root = sorted(multi_root_traces, key=lambda x: trace_root_count[x], reverse=True)[:10]
        for tid in sorted_multi_root:
            print(f"   TraceID {tid}ï¼š{trace_root_count[tid]} ä¸ªæ ¹èŠ‚ç‚¹")

    return {
        "total_traces": total_trace_count,
        "multi_root_traces": multi_root_count,
        "multi_root_trace_list": multi_root_traces
    }

if __name__ == "__main__":
    # å‘½ä»¤è¡Œå‚æ•°è§£æï¼ˆæ”¯æŒè‡ªå®šä¹‰åˆ—åå’Œé»˜è®¤CSVè·¯å¾„ï¼‰
    parser = argparse.ArgumentParser(description="ç»Ÿè®¡CSVä¸­å­˜åœ¨å¤šæ ¹èŠ‚ç‚¹çš„Traceæ•°é‡")
    # æ”¹ä¸ºå¯é€‰å‚æ•°ï¼Œè®¾ç½®é»˜è®¤CSVè·¯å¾„ï¼Œæ”¯æŒç›´æ¥è¿è¡Œ
    parser.add_argument("-f", "--file", 
                        default="/root/wzc/tracezly_rca/tianchi_processed_data2.csv",
                        dest="csv_file",
                        help="CSVæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šnormal_traces_2e5_1622_mapped.csvï¼‰")
    parser.add_argument("--trace-col", 
                        default="TraceID",
                        help="TraceIDåˆ—åï¼ˆé»˜è®¤ï¼šTraceIDï¼‰")
    parser.add_argument("--span-col", 
                        default="SpanID",
                        help="SpanIDåˆ—åï¼ˆé»˜è®¤ï¼šSpanIDï¼‰")
    parser.add_argument("--parent-col", 
                        default="ParentID",
                        help="ParentIDåˆ—åï¼ˆé»˜è®¤ï¼šParentIDï¼‰")
    
    args = parser.parse_args()
    
    # æ‰§è¡Œç»Ÿè®¡
    count_multi_root_traces(
        csv_file_path=args.csv_file,
        trace_col=args.trace_col,
        span_col=args.span_col,
        parent_col=args.parent_col
    )